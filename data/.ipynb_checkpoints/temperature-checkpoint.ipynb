{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from scipy.io import netcdf\n",
    "from netCDF4 import Dataset as NetCDFFile \n",
    "import pyproj\n",
    "import numpy as np\n",
    "import ftplib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.variables import *  # imports variables such as lat_lims, lon_lims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_data(filename):\n",
    "    \"\"\"\n",
    "    Opens up netcdf file to view its content, such as variables and dimensions.\n",
    "    \"\"\"\n",
    "    data = NetCDFFile(filename)\n",
    "    print(data)\n",
    "    print(data.variables['time'])\n",
    "\n",
    "def FTPimprort(FILE_NAME):\n",
    "    \"\"\"\n",
    "    Open up temperature netcdf file and extract content.\n",
    "    File data is from https://psl.noaa.gov/thredds/catalog/Datasets/cpc_global_temp/catalog.html\n",
    "    \"\"\"\n",
    "    path = '/Datasets/cpc_global_temp/' # path is the location of the file in the ftp server\n",
    "    FILE_NAME = 't%s.%d.nc' % (data_type, year) # filename is the name + extension of the file \n",
    "\n",
    "    # connect to FTP server and download file\n",
    "    ftp = ftplib.FTP(\"ftp2.psl.noaa.gov\") \n",
    "    ftp.login() \n",
    "    ftp.cwd(path)\n",
    "    ftp.retrbinary(\"RETR \" + FILE_NAME ,open(FILE_NAME, 'wb').write)\n",
    "    ftp.quit()\n",
    "    \n",
    "    nc_data = NetCDFFile(FILE_NAME)  # load NetCDF file\n",
    "    os.remove(FILE_NAME)  # remove downloaded file\n",
    "    \n",
    "    return nc_data\n",
    "\n",
    "def get_area_coords(coordinate_list, lims):\n",
    "    \"\"\"\n",
    "    Given an array of coordinates and coordinate limits specified, return the\n",
    "    index corresponding to those limits and the clipped array.\n",
    "    \"\"\"\n",
    "    idx = []\n",
    "    for lim in lims:\n",
    "        minimum = float(\"inf\")\n",
    "    for i in range(len(coordinate_list)):\n",
    "        if abs(lim - coordinate_list[i]) < minimum:\n",
    "            final_value = i\n",
    "            minimum = abs(lim - coordinate_list[i])\n",
    "    idx.append(final_value)\n",
    "    area_coords = coordinate_list[idx[0]: idx[1]]\n",
    "    return area_coords, idx\n",
    "\n",
    "def extract_temp_data(data, lat_lims, lon_lims, data_type):\n",
    "    \"\"\"\n",
    "    Open up temperature netcdf file and extract content, including clipping to the\n",
    "    latitude and longitude limits of interest (specified in variables.py).\n",
    "    \"\"\"\n",
    "    values = data.variables['t'+ data_type][:]  # tmin or tmax\n",
    "    time = data.variables['time'][:]\n",
    "    lat = data.variables['lat'][:]\n",
    "    lon = data.variables['lon'][:]\n",
    "    area_lat, idx_lat = get_area_coords(lat, lat_lims[::-1]) # reverse latitide limits\n",
    "    area_lon, idx_lon = get_area_coords(lon, lon_lims)\n",
    "    area_values = values[:, idx_lat[0]:idx_lat[1], idx_lon[0]:idx_lon[1]]\n",
    "    dict_temp = {'values': values,\n",
    "          'area_lat': area_lat,\n",
    "          'area_lon': area_lon,\n",
    "          'time': time,\n",
    "          'area_values': area_values}\n",
    "    return dict_temp\n",
    "\n",
    "def average_temp_data(area_value,from_year,to_year):\n",
    "    \"\"\"\n",
    "    Takes daily temperature and averages total over the \"wet\"\n",
    "    six months of the year (specified in variables.py).\n",
    "    Returns:\n",
    "        six_month_values: np.array with dimensions (year index, lat, lon)\n",
    "    \"\"\"\n",
    "    area_average = np.empty((0,area_value.shape[1], area_value.shape[2]))\n",
    "    for i in range(0,to_year-from_year,1):\n",
    "        area = np.mean(area_value[(305+(365*i)):(305+(365*i))+150,:,:],axis=0)\n",
    "        area_average = np.concatenate((area_average,np.reshape(area,(1,area_value.shape[1], area_value.shape[2]))))\n",
    "    return area_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert start and end year variable input to using input\n",
    "from_year = year_start\n",
    "to_year = year_end + 1\n",
    "types = [\"max\", \"min\"]\n",
    "\n",
    "# convert lat and long variable input to using input\n",
    "lat_lims_var = [lat_lims[1], lat_lims[0]]\n",
    "lon_lims_var = [lon_lims[0] + 360, lon_lims[1] + 360]\n",
    "\n",
    "dict_tmax = dict()\n",
    "dict_tmin = dict()\n",
    "\n",
    "# for loop over the years and max and min\n",
    "for year in range(from_year, to_year+1, 1): # to include to_year\n",
    "    for data_type in types:\n",
    "        FILE_NAME = 't%s.%d.nc' % (data_type, year) # filename + extension of the file\n",
    "        # path = 'drive/Shareddrives/CS230 Project/preprocessing_temperature/' + FILE_NAME\n",
    "\n",
    "        # load NetCDF max and min files\n",
    "        if data_type == \"max\":\n",
    "            data = FTPimprort(FILE_NAME)\n",
    "            dict_tmax[year] = extract_temp_data(data, lat_lims_var, lon_lims_var, data_type)\n",
    "\n",
    "        else:\n",
    "            data = FTPimprort(FILE_NAME)\n",
    "            dict_tmin[year] = extract_temp_data(data, lat_lims_var, lon_lims_var, data_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.25 33.75 34.25 34.75 35.25 35.75 36.25 36.75 37.25 37.75 38.25 38.75\n",
      " 39.25 39.75 40.25 40.75 41.25 41.75 42.25]\n",
      "[-125.25 -124.75 -124.25 -123.75 -123.25 -122.75 -122.25 -121.75 -121.25\n",
      " -120.75 -120.25 -119.75 -119.25 -118.75 -118.25 -117.75 -117.25 -116.75\n",
      " -116.25 -115.75 -115.25 -114.75]\n"
     ]
    }
   ],
   "source": [
    "# combine data from all years\n",
    "tmin_all = np.concatenate([dict_tmin[year]['area_values'] for year in range(from_year, to_year+1)])\n",
    "tmax_all = np.concatenate([dict_tmax[year]['area_values'] for year in range(from_year, to_year+1)])\n",
    "\n",
    "# create average values\n",
    "SIX_MONTH_VALUES_TMIN = average_temp_data(tmin_all,from_year,to_year)\n",
    "SIX_MONTH_VALUES_TMAX = average_temp_data(tmax_all,from_year,to_year)\n",
    "\n",
    "LAT = dict_tmin[from_year]['area_lat'][::-1]\n",
    "LON = dict_tmin[from_year]['area_lon']-360\n",
    "YEARS = np.arange(from_year, to_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
